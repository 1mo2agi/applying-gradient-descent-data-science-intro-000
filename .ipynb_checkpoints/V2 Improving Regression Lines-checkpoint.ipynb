{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Regression Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we derived the functions that we help us descend along our cost functions efficiently.  Remember that this technique is not so different from what we saw with using the derivative to tell us our next step size and direction in two dimensions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./tangent-lines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we used the slope of the tangent line at each point, to tell us how large of a step to take next.  Now with the our cost curve being a function of changing variables of $m$ and $b$ things appear more complicated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./gradientdescent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But really it's just the same approach.  Just like we can calculate the use derivative of a function like $x^2$ to calculate the slope at a given value of $x$ on the graph, and thus how far to move next.  Here, we use the partial derivative with respect to the slope and with respect to the y-intercept, to calculate the amount to move next in either direction, and thus to steer us towards our minimum.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./maps-pointer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing our gradient descent formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, we already did the hard work of deriving these formulas.  Now we get to see the fruit of our labor.  The following formulas tell us how to update regression variables of $m$ and $b$ to approach a \"best fit\" line.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\frac{dJ}{dm}J(m,b) = -2*\\sum x(mx + b - y)$  \n",
    "* $ \\frac{dJ}{db}J(m,b) = -2*\\sum(mx + b - y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the formulas above tell us to take some dataset, with values of $x$ and $y$, and then given a regression formula with values $m$ and $b$, just plug in our values and move in that direction.  Let's simplify these formulas conceptually a little bit: \n",
    "\n",
    "* $ \\frac{dJ}{dm}J(m,b) = -2*\\sum x(mx + b - y) = -2*\\sum x(\\overline{y} - y) = -2*\\sum x\\epsilon$  \n",
    "* $ \\frac{dJ}{db}J(m,b) = -2*\\sum(mx + b - y) = -2*\\sum(\\overline{y} - y) = -2*\\sum \\epsilon$\n",
    "\n",
    "If you step through the above lines, you can see how we can state these formulas in terms of error. As expressed above, we calculate the update to our slope by multiplying each error by the $x$ value and adding these terms up, and then multiplying by negative two.  We calculate the update to the $b$ value by adding up all of the errors at each point, and multiplying by negative two.\n",
    "\n",
    "Let's get a sense of how this would translate into code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** perhaps here, show our approach so far in pseudocode **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking our approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we are about to turn these formulas into code, but before we do, we need to make just a couple of tweaks to our approach.\n",
    "\n",
    "The first one is obvious if we think about what these formulas are really telling us to do.  Look at the graph below, and think about what it means to change each of our $m$ and $b$ variables by at least the sum of our errors.  That would be an enormous change.  To ensure that we are not making such drastic changes, we multiply each of these partial derivatives by a learning rate, where the learning rate is something small like $.0001$.  The learning rate is represented by the Greek letter eta, so $\\eta = .0001$ means the learning rate is $.0001$.\n",
    "\n",
    "This is ok, because we in a multivariable formula like $J(m,b)$, we should really think of our derivatives as steering us in the correct direction, that is in making sure we are make the correct proportional changes to $m$ and $b$.  So scaling down these changes to make sure we don't move too works fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./regression-scatter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our second tweak, the because the more the number of points, the larger our error, we can correct for this by multiplying our changes by $1/n$.\n",
    "\n",
    "Making these changes, our formula looks like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "learning_rate = .0001\n",
    "n = len(updated_shows)\n",
    "b_gradient = 0\n",
    "m_gradient = 0 \n",
    "N = float(len(updated_shows))\n",
    "for i in range(len(points)):\n",
    "    b_gradient += -(1/n)*(error_at_point_x)\n",
    "    m_gradient += -(1/n)*(error_at_point_x*x)\n",
    "\n",
    "new_b = b_current - (learningRate * b_gradient)\n",
    "new_m = m_current - (learningRate * m_gradient)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So note from the code above, that our b and m gradients start at zero.  In other words, we begin by assuming that we should not change b or m at all.  Then for each point, we see the error of our current regression line.  For each point, we adjust our b gradient by the error, divided by the number of points.  For the m_gradient, we adjust our m_gradient to by the error at a given point multiplied by the x value of that point.  \n",
    "\n",
    "Finally, we update our value of b by the amount of the gradient.  Well, the amount of the gradient times by this learning rate.  The learning rate is simply to scale down the size of our update to our values - so that we don't overshoot the mark.  Remember that as long as we move in the right direction, we will get there.\n",
    "\n",
    "So that is our our gradient descent process.  Start with an initial regression line with values of m and b.  Then for each point, calculate how the regression line fares against the actual point (that is, find the error).  Update the gradient, so that we will be moving the value in the opposite direction of the error.  And after running through all of the points, and adjusting the gradient with every point, update the overall value of b and m by their respective gradients, scaled down by a small learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, let's see our gradient descent formulas in action.  Then, we can develop some intuition as to why they work and where they came from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing our gradient descent formulas in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's translate our step gradient process into some real live code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_show = {'x': 30, 'y': 45}\n",
    "second_show = {'x': 40, 'y': 60}\n",
    "third_show = {'x': 100, 'y': 150}\n",
    "\n",
    "updated_shows = [first_show, second_show, third_show]\n",
    "\n",
    "def step_gradient(b_current, m_current, points):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    learning_rate = .0001\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i]['x']\n",
    "        y = points[i]['y']\n",
    "        b_gradient += -(1/N) * (y - ((m_current * x) + b_current))\n",
    "        m_gradient += -(1/N) * x * (y - ((m_current * x) + b_current))\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return {'b': new_b, 'm': new_m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 0.0085, 'm': 0.6249999999999999}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 0\n",
    "m = 0\n",
    "\n",
    "step_gradient(b, m, updated_shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So just looking at input and output, we begin by setting $b$ and $m$ to 0, 0.  Then from our step_gradient function, we recieve new values of b and m of .0085 and .6245.  Now what we need to do, is take another step in the correct direction by calling our step gradient function with our updated values of b and m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 0.01345805, 'm': 0.9894768333333332}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_b = 0.0085\n",
    "updated_m = 0.6249\n",
    "step_gradient(updated_b, updated_m, updated_shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this, say, 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set our initial step with m and b values, and the corresponding error.\n",
    "b = 0\n",
    "m = 0\n",
    "iterations = []\n",
    "for i in range(10):\n",
    "    iteration = step_gradient(b, m, updated_shows)\n",
    "    # {'b': value, 'm': value}\n",
    "    b = iteration['b']\n",
    "    m = iteration['m']\n",
    "    # update values of b and m\n",
    "    iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'b': 0.0085, 'm': 0.6249999999999999},\n",
       " {'b': 0.013457483333333336, 'm': 0.9895351666666665},\n",
       " {'b': 0.016348771640555558, 'm': 1.20215258815},\n",
       " {'b': 0.018034938763874835, 'm': 1.3261630333815368},\n",
       " {'b': 0.01901821141416974, 'm': 1.398492904819568},\n",
       " {'b': 0.019591516465717437, 'm': 1.4406797579467343},\n",
       " {'b': 0.019925705352372706, 'm': 1.4652855068756228},\n",
       " {'b': 0.020120428242875608, 'm': 1.4796369666804499},\n",
       " {'b': 0.02023380672219544, 'm': 1.4880075481368862},\n",
       " {'b': 0.020299740568747532, 'm': 1.4928897448417577}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our m and b values both update with each step.  Not only that, but with each step, our m and b values are updated less and less as the lines they produce have lower errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this visually.  We'll write a method called `to_line` that takes an iterations and changes it to produce a data structure we can use for a frame in an animation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'x': [0, 100], 'y': [0.0085, 62.508499999999984]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_line(m, b):\n",
    "    initial_x = 0\n",
    "    ending_x = 100\n",
    "    initial_y = m*initial_x + b\n",
    "    ending_y = m*ending_x + b\n",
    "    return {'data': [{'x': [initial_x, ending_x], 'y': [initial_y, ending_y]}]}\n",
    "\n",
    "frames = list(map(lambda iteration: to_line(iteration['m'], iteration['b']),iterations))\n",
    "frames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how our regression line changes, and approaches our data, with each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "x": [
          0
         ],
         "y": [
          0
         ]
        },
        {
         "mode": "markers",
         "x": [
          30,
          40,
          100
         ],
         "y": [
          45,
          60,
          150
         ]
        }
       ],
       "frames": [
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.0085,
            62.508499999999984
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.013457483333333336,
            98.96697415
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.016348771640555558,
            120.23160758664055
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.018034938763874835,
            132.63433827691753
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.01901821141416974,
            139.86830869337098
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.019591516465717437,
            144.08756731113914
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.019925705352372706,
            146.54847639291464
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.020120428242875608,
            147.98381709628785
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.02023380672219544,
            148.82098862041082
           ]
          }
         ]
        },
        {
         "data": [
          {
           "x": [
            0,
            100
           ],
           "y": [
            0.020299740568747532,
            149.30927422474454
           ]
          }
         ]
        }
       ],
       "layout": {
        "title": "Regression Line",
        "updatemenus": [
         {
          "buttons": [
           {
            "args": [
             null
            ],
            "label": "Play",
            "method": "animate"
           }
          ],
          "type": "buttons"
         }
        ],
        "xaxis": {
         "autorange": false,
         "range": [
          0,
          110
         ]
        },
        "yaxis": {
         "autorange": false,
         "range": [
          0,
          160
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"f96d8c1e-a0c5-4a01-9b2b-5617c257db24\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            'f96d8c1e-a0c5-4a01-9b2b-5617c257db24',\n",
       "            [{\"x\": [0], \"y\": [0]}, {\"x\": [30, 40, 100], \"y\": [45, 60, 150], \"mode\": \"markers\"}],\n",
       "            {\"xaxis\": {\"range\": [0, 110], \"autorange\": false}, \"yaxis\": {\"range\": [0, 160], \"autorange\": false}, \"title\": \"Regression Line\", \"updatemenus\": [{\"type\": \"buttons\", \"buttons\": [{\"label\": \"Play\", \"method\": \"animate\", \"args\": [null]}]}]},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('f96d8c1e-a0c5-4a01-9b2b-5617c257db24',[{\"data\": [{\"x\": [0, 100], \"y\": [0.0085, 62.508499999999984]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.013457483333333336, 98.96697415]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.016348771640555558, 120.23160758664055]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.018034938763874835, 132.63433827691753]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.01901821141416974, 139.86830869337098]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.019591516465717437, 144.08756731113914]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.019925705352372706, 146.54847639291464]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.020120428242875608, 147.98381709628785]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.02023380672219544, 148.82098862041082]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.020299740568747532, 149.30927422474454]}]}]);}).then(function(){Plotly.animate('f96d8c1e-a0c5-4a01-9b2b-5617c257db24');})\n",
       "        });</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"f96d8c1e-a0c5-4a01-9b2b-5617c257db24\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            'f96d8c1e-a0c5-4a01-9b2b-5617c257db24',\n",
       "            [{\"x\": [0], \"y\": [0]}, {\"x\": [30, 40, 100], \"y\": [45, 60, 150], \"mode\": \"markers\"}],\n",
       "            {\"xaxis\": {\"range\": [0, 110], \"autorange\": false}, \"yaxis\": {\"range\": [0, 160], \"autorange\": false}, \"title\": \"Regression Line\", \"updatemenus\": [{\"type\": \"buttons\", \"buttons\": [{\"label\": \"Play\", \"method\": \"animate\", \"args\": [null]}]}]},\n",
       "            {\"showLink\": true, \"linkText\": \"Export to plot.ly\"}\n",
       "        ).then(function () {return Plotly.addFrames('f96d8c1e-a0c5-4a01-9b2b-5617c257db24',[{\"data\": [{\"x\": [0, 100], \"y\": [0.0085, 62.508499999999984]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.013457483333333336, 98.96697415]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.016348771640555558, 120.23160758664055]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.018034938763874835, 132.63433827691753]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.01901821141416974, 139.86830869337098]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.019591516465717437, 144.08756731113914]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.019925705352372706, 146.54847639291464]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.020120428242875608, 147.98381709628785]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.02023380672219544, 148.82098862041082]}]}, {\"data\": [{\"x\": [0, 100], \"y\": [0.020299740568747532, 149.30927422474454]}]}]);}).then(function(){Plotly.animate('f96d8c1e-a0c5-4a01-9b2b-5617c257db24');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "x_values_of_shows = list(map(lambda show: show['x'], updated_shows))\n",
    "y_values_of_shows = list(map(lambda show: show['y'], updated_shows))\n",
    "figure = {'data': [{'x': [0], 'y': [0]}, {'x': x_values_of_shows, 'y': y_values_of_shows, 'mode': 'markers'}],\n",
    "          'layout': {'xaxis': {'range': [0, 110], 'autorange': False},\n",
    "                     'yaxis': {'range': [0,160], 'autorange': False},\n",
    "                     'title': 'Regression Line',\n",
    "                     'updatemenus': [{'type': 'buttons',\n",
    "                                      'buttons': [{'label': 'Play',\n",
    "                                                   'method': 'animate',\n",
    "                                                   'args': [None]}]}]\n",
    "                    },\n",
    "          'frames': frames}\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 40, 100]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values_of_shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
